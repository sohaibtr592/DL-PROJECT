import json
import joblib
import numpy as np
import pandas as pd
import streamlit as st

import torch
import torch.nn as nn

# =========================================
# 1) Chargement des ressources
# =========================================

@st.cache_data
def load_data_and_features():
    df = pd.read_csv("df_ready_for_app.csv")
    with open("feature_cols.json", "r") as f:
        feature_cols = json.load(f)
    return df, feature_cols

@st.cache_resource
def load_rf_model():
    return joblib.load("random_forest.pkl")

class LSTMClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):
        super(LSTMClassifier, self).__init__()
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True
        )
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        out, (hn, cn) = self.lstm(x)
        last_hidden = hn[-1]
        logits = self.fc(last_hidden)
        return logits

@st.cache_resource
def load_lstm_and_scaler(input_dim, num_classes, hidden_dim=64, num_layers=1):
    device = torch.device("cpu")
    model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes).to(device)
    state_dict = torch.load("lstm_rmsprop.pt", map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    scaler = joblib.load("scaler_lstm.pkl")
    return model, scaler, device

def build_sequences_input(df, feature_cols, seq_len=10):
    df_seq = df.sort_values("timestamp").reset_index(drop=True)
    X_all = df_seq[feature_cols].values.astype("float32")
    return df_seq, X_all

def create_seq_from_index(X_all_scaled, idx_last, seq_len=10):
    start = idx_last - seq_len + 1
    X_seq = X_all_scaled[start:idx_last+1, :]
    return X_seq

# =========================================
# 2) CONFIG et √©tat (session_state)
# =========================================

st.set_page_config(page_title="Time Series ML & DL Demo", layout="wide")

if "idx_last" not in st.session_state:
    st.session_state.idx_last = 9   # par d√©faut : premi√®re position possible

SEQ_LEN = 10

st.title("üïí Classification de signaux capteurs ‚Äì ML & Deep Learning")

st.markdown("""
Application interactive pour comparer un **mod√®le de Machine Learning classique (RandomForest)**  
et un **mod√®le de Deep Learning s√©quentiel (LSTM + RMSprop)** sur des donn√©es de capteurs temporelles.
""")

df, feature_cols = load_data_and_features()
df_seq, X_all = build_sequences_input(df, feature_cols, seq_len=SEQ_LEN)

num_features = len(feature_cols)
num_classes = len(np.unique(df["id_class"]))

# mapping id_class -> id_group (optionnel)
if "id_group" in df_seq.columns:
    map_df = df_seq[["id_class", "id_group"]].drop_duplicates().sort_values("id_class")
    idclass_to_group = dict(zip(map_df["id_class"], map_df["id_group"]))
else:
    idclass_to_group = {}

# =========================================
# 3) Sidebar : navigation dans le temps
# =========================================

st.sidebar.header("‚öôÔ∏è Navigation temporelle")

max_idx = len(df_seq) - 1
min_idx = SEQ_LEN - 1

# boutons pr√©c√©dent / suivant / al√©atoire
col_b1, col_b2, col_b3 = st.sidebar.columns(3)
with col_b1:
    if st.button("‚¨ÖÔ∏è Prev"):
        st.session_state.idx_last = max(min_idx, st.session_state.idx_last - 1)
with col_b2:
    if st.button("‚û°Ô∏è Next"):
        st.session_state.idx_last = min(max_idx, st.session_state.idx_last + 1)
with col_b3:
    if st.button("üé≤ Random"):
        st.session_state.idx_last = int(np.random.randint(min_idx, max_idx+1))

# slider synchronis√© avec session_state
st.session_state.idx_last = st.sidebar.slider(
    "Index temporel (position dans la s√©rie)",
    min_value=min_idx,
    max_value=max_idx,
    value=st.session_state.idx_last
)

idx_last = st.session_state.idx_last

st.sidebar.write(f"Index s√©lectionn√© : {idx_last}")

# choix de la feature √† tracer
feature_to_plot = st.sidebar.selectbox(
    "Feature √† afficher sur la fen√™tre temporelle :",
    feature_cols,
    index=0
)

# =========================================
# 4) Informations sur l'observation
# =========================================

row = df_seq.iloc[idx_last]
true_class = int(row["id_class"])
true_group = idclass_to_group.get(true_class, "N/A")

st.subheader("üßæ Observation s√©lectionn√©e")

c1, c2 = st.columns(2)

with c1:
    st.write("**Timestamp :**", row["timestamp"])
    st.write("**Classe r√©elle (id_class) :**", true_class)
    st.write("**id_group associ√© :**", true_group)

with c2:
    st.write("**Features au dernier instant (t)**")
    st.dataframe(row[feature_cols].to_frame().T)

st.markdown("---")

# =========================================
# 5) Contexte temporel (fen√™tre LSTM)
# =========================================

st.subheader("üìà Contexte temporel utilis√© par le LSTM")

start_idx = idx_last - SEQ_LEN + 1
window_df = df_seq.iloc[start_idx:idx_last+1]

st.line_chart(
    window_df.set_index("timestamp")[feature_to_plot],
    height=250
)
st.caption(f"√âvolution de `{feature_to_plot}` sur les {SEQ_LEN} derniers instants avant t (entr√©e du LSTM).")

st.markdown("---")

# =========================================
# 6) Onglets pour comparer RF vs LSTM
# =========================================

tab_rf, tab_lstm = st.tabs(["üå≤ RandomForest (ML)", "üß† LSTM + RMSprop (DL)"])

# ---------- RandomForest ----------
with tab_rf:
    st.subheader("üå≤ Pr√©diction avec RandomForest (Machine Learning classique)")
    st.markdown("""
    Mod√®le d'arbres de d√©cision **non s√©quentiel** :  
    il consid√®re uniquement le vecteur de features √† l'instant t (et les lags d√©j√† inclus comme colonnes).
    """)

    rf = load_rf_model()
    X_rf = row[feature_cols].values.reshape(1, -1)

    pred_class_rf = int(rf.predict(X_rf)[0])
    proba_rf = rf.predict_proba(X_rf)[0]

    st.write(f"**Classe pr√©dite (id_class) :** `{pred_class_rf}`")
    st.write(f"**Classe r√©elle (id_class) :** `{true_class}`")

    proba_df_rf = pd.DataFrame({
        "id_class": rf.classes_,
        "probabilit√©": proba_rf
    }).sort_values("probabilit√©", ascending=False)

    c_rf1, c_rf2 = st.columns(2)
    with c_rf1:
        st.write("**Probabilit√©s par classe :**")
        st.dataframe(proba_df_rf)
    with c_rf2:
        st.bar_chart(
            proba_df_rf.set_index("id_class")["probabilit√©"],
            height=250
        )

# ---------- LSTM ----------
with tab_lstm:
    st.subheader("üß† Pr√©diction avec LSTM + RMSprop (Deep Learning s√©quentiel)")
    st.markdown("""
    Mod√®le **LSTM** : il prend en entr√©e une s√©quence de longueur 10  
    (les 10 derniers instants avant t) et produit une pr√©diction pour la classe au temps t.
    """)

    model_lstm, scaler_lstm, device = load_lstm_and_scaler(
        input_dim=num_features,
        num_classes=num_classes,
        hidden_dim=64,
        num_layers=1
    )

    # standardiser toutes les features
    X_all_scaled = scaler_lstm.transform(X_all)
    X_seq = create_seq_from_index(X_all_scaled, idx_last, seq_len=SEQ_LEN)

    X_seq_t = torch.tensor(X_seq, dtype=torch.float32).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model_lstm(X_seq_t)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
        pred_class_lstm = int(np.argmax(probs))

    st.write(f"**Classe pr√©dite (id_class) :** `{pred_class_lstm}`")
    st.write(f"**Classe r√©elle (id_class) :** `{true_class}`")

    classes_lstm = sorted(df["id_class"].unique())
    proba_df_lstm = pd.DataFrame({
        "id_class": classes_lstm,
        "probabilit√©": probs
    }).sort_values("probabilit√©", ascending=False)

    c_l1, c_l2 = st.columns(2)
    with c_l1:
        st.write("**Probabilit√©s par classe :**")
        st.dataframe(proba_df_lstm)
    with c_l2:
        st.bar_chart(
            proba_df_lstm.set_index("id_class")["probabilit√©"],
            height=250
        )

st.markdown("""
---
‚úÖ *Cette interface permet de comparer en direct un mod√®le **ML tabulaire (RandomForest)**  
et un mod√®le **DL s√©quentiel (LSTM)** sur des donn√©es de capteurs temporelles.*
""")
